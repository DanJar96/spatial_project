{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1080bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import sklearn\n",
    "import geopandas as gpd\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "import os\n",
    "\n",
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_rows', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c3ac9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dante/SpatialData/spatial_project/scripts'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting output dictionary\n",
    "output_dir = '/home/dante/SpatialData/spatial_project/data/output/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33e3c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading final data\n",
    "df = pd.read_csv('/home/dante/SpatialData/spatial_project/data/processed/master_data.csv').iloc[:,0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf855a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['province', 'Y-W', 'newcases', 'newcases_tminus1', 'newcases_tminus2',\n",
       "       'newcases_tminus3', 'newcases_tminus4', 'newcases_tplus1',\n",
       "       'newcases_tplus2', 'newcases_tplus4', 'spc_tminus1', 'spc_tminus2',\n",
       "       'spc_tminus3', 'spc_tminus4', 'temp_min_tminus1', 'temp_min_tminus2',\n",
       "       'temp_min_tminus3', 'temp_min_tminus4', 'temp_max_tminus1',\n",
       "       'temp_max_tminus2', 'temp_max_tminus3', 'temp_max_tminus4',\n",
       "       'retail_tminus1', 'retail_tminus2', 'retail_tminus3', 'retail_tminus4',\n",
       "       'grocery_tminus1', 'grocery_tminus2', 'grocery_tminus3',\n",
       "       'grocery_tminus4', 'parks_tminus1', 'parks_tminus2', 'parks_tminus3',\n",
       "       'parks_tminus4', 'transit_tminus1', 'transit_tminus2',\n",
       "       'transit_tminus3', 'transit_tminus4', 'workplaces_tminus1',\n",
       "       'workplaces_tminus2', 'workplaces_tminus3', 'workplaces_tminus4',\n",
       "       'residential_tminus1', 'residential_tminus2', 'residential_tminus3',\n",
       "       'residential_tminus4', '2019employment_rate',\n",
       "       '2019intermunicipal_migration_rate', '2019annual_contrib_margin',\n",
       "       '2019share_age_64', '2019number_workplaces'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6eef3424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choosehorizon(dataframe,pred : int,lags):\n",
    "    \"\"\"\n",
    "    This function takes in the master dataframe and spits out the lags that you want to include,\n",
    "    and then sorts the data so that it's easier to look at.\n",
    "    \"\"\"\n",
    "    if pred not in [1,2,4]:\n",
    "        print(f\"Sorry, but the only available prediction horizons are 1,2 and 4 weeks ahead!\")\n",
    "        return None\n",
    "    elif (max(lags) > 4) or (min(lags) < 1):\n",
    "        if len(lags) == 0:\n",
    "            print(\"You have specified zero lags! Nonsense!\")\n",
    "        else: print(\"Your lags are out of bounds...\")\n",
    "    \n",
    "    lagcols = [col for col in list(dataframe.columns) if 'tminus' in col]\n",
    "    \n",
    "    lagschosen = []\n",
    "    for lag in lags:\n",
    "        lagschosen += [col for col in lagcols if str(lag) in col]\n",
    "        \n",
    "    lagschosen.sort()\n",
    "    sociocols = [col for col in list(dataframe.columns) if '2019' in col]\n",
    "    indices = ['Y-W','province']\n",
    "    y = f\"newcases_tplus{pred}\"\n",
    "    \n",
    "    allcols = indices + [y] + lagschosen + sociocols\n",
    "    \n",
    "    # Given lags, take out data that contains NaNs due to data unavailability\n",
    "    # First week when we have data is 2020-10, so add up weeks according to lags..\n",
    "    max_lag = max(lags)\n",
    "    first_week = f\"2020-{10+max_lag}\"\n",
    "    \n",
    "    # Given that we are predicting into the future, we need to take off as many weeks as we\n",
    "    # are predicting into the future for, because otherwise we have NaNs..\n",
    "    last_week = f\"2022-{10-pred}\"\n",
    "    \n",
    "    # We also need to take care of the fact that we only have Google Mobility data up to 2021-52\n",
    "    last_week_google = f\"2021-52\"\n",
    "    \n",
    "    last_effective_week = [last_week,last_week_google]\n",
    "    last_effective_week.sort()\n",
    "    dataframe = dataframe[(dataframe['Y-W'] >= first_week) & (dataframe['Y-W'] <= last_effective_week[0])]\n",
    "    dataframe.reset_index(drop=True,inplace=True)\n",
    "    return dataframe[allcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4889c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = choosehorizon(df,2,[1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6efd61a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1656, 48)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1209759c",
   "metadata": {},
   "source": [
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c45519db",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 50 # week\n",
    "testing_size = 1 # week\n",
    "num_counties = len(data.province.value_counts().index)\n",
    "time_steps = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9441b9a",
   "metadata": {},
   "source": [
    "## Model tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667c5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_r2_xgb = dict()\n",
    "train_rmse_xgb = dict()\n",
    "train_mae_xgb = dict()\n",
    "test_rmse_xgb = dict()\n",
    "test_mae_xgb = dict()\n",
    "tuned_params_xgb = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8b48e3",
   "metadata": {},
   "source": [
    "## Model grid setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d94268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Hyperparameters. Please refer to the SI for more information\n",
    "xgb_params = dict(learning_rate=np.arange(0.05,0.3,0.05), \n",
    "                     n_estimators=np.arange(100,1000,100), \n",
    "                     gamma = np.arange(1,10,1),\n",
    "                     subsample = np.arange(0.1,0.5,0.05),\n",
    "                     max_depth=[int(i) for i in np.arange(1,10,1)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af093a7",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffea3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(time_steps):\n",
    "    \n",
    "    training_df = data.iloc[:(i+training_size)*num_counties,:]\n",
    "    testing_df = data.iloc[(i+training_size)*num_counties:(i+training_size+testing_size)*num_counties,:]\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
