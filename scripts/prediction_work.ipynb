{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f6c81ce",
      "metadata": {
        "id": "3f6c81ce"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np \n",
        "import sklearn\n",
        "from scipy.stats import norm\n",
        "import time\n",
        "import os\n",
        "\n",
        "import xgboost\n",
        "\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit, RandomizedSearchCV,GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_rows', 200)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c-PTUu0mw47",
        "outputId": "a9893443-c8da-4e53-9f91-4c728f38a964"
      },
      "id": "2c-PTUu0mw47",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1484d25",
      "metadata": {
        "id": "f1484d25"
      },
      "outputs": [],
      "source": [
        "# Setting output dictionary\n",
        "output_dir = '/home/dante/SpatialData/spatial_project/data/output/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2eafcae8",
      "metadata": {
        "id": "2eafcae8"
      },
      "outputs": [],
      "source": [
        "# Loading final data\n",
        "df = pd.read_csv('/content/drive/MyDrive/spatial_data/final_project/master_data.csv').iloc[:,0:-1]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "google_data_list = [\n",
        "retail,\n",
        "grocery,\n",
        "parks,\n",
        "transit,\n",
        "workplaces,\n",
        "residential\n",
        "]\n"
      ],
      "metadata": {
        "id": "x8urQGo26upi"
      },
      "id": "x8urQGo26upi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "507c689b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "507c689b",
        "outputId": "a49bdfc7-8889-40dd-a0d0-86c53444af08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['province', 'Y-W', 'newcases', 'newcases_tminus1', 'newcases_tminus2',\n",
              "       'newcases_tminus3', 'newcases_tminus4', 'newcases_tplus1',\n",
              "       'newcases_tplus2', 'newcases_tplus4', 'spc_tminus1', 'spc_tminus2',\n",
              "       'spc_tminus3', 'spc_tminus4', 'temp_min_tminus1', 'temp_min_tminus2',\n",
              "       'temp_min_tminus3', 'temp_min_tminus4', 'temp_max_tminus1',\n",
              "       'temp_max_tminus2', 'temp_max_tminus3', 'temp_max_tminus4',\n",
              "       'retail_tminus1', 'retail_tminus2', 'retail_tminus3', 'retail_tminus4',\n",
              "       'grocery_tminus1', 'grocery_tminus2', 'grocery_tminus3',\n",
              "       'grocery_tminus4', 'parks_tminus1', 'parks_tminus2', 'parks_tminus3',\n",
              "       'parks_tminus4', 'transit_tminus1', 'transit_tminus2',\n",
              "       'transit_tminus3', 'transit_tminus4', 'workplaces_tminus1',\n",
              "       'workplaces_tminus2', 'workplaces_tminus3', 'workplaces_tminus4',\n",
              "       'residential_tminus1', 'residential_tminus2', 'residential_tminus3',\n",
              "       'residential_tminus4', '2019employment_rate',\n",
              "       '2019intermunicipal_migration_rate', '2019annual_contrib_margin',\n",
              "       '2019share_age_64', '2019number_workplaces'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f756bccd",
      "metadata": {
        "id": "f756bccd"
      },
      "outputs": [],
      "source": [
        "def choosehorizon(dataframe,pred : int,lags):\n",
        "    \"\"\"\n",
        "    This function takes in the master dataframe and spits out the lags that you want to include,\n",
        "    and then sorts the data so that it's easier to look at.\n",
        "    \"\"\"\n",
        "    if pred not in [1,2,4]:\n",
        "        print(f\"Sorry, but the only available prediction horizons are 1,2 and 4 weeks ahead!\")\n",
        "        return None\n",
        "    elif (max(lags) > 4) or (min(lags) < 1):\n",
        "        if len(lags) == 0:\n",
        "            print(\"You have specified zero lags! Nonsense!\")\n",
        "        else: print(\"Your lags are out of bounds...\")\n",
        "    \n",
        "    lagcols = [col for col in list(dataframe.columns) if 'tminus' in col]\n",
        "    \n",
        "    lagschosen = []\n",
        "    for lag in lags:\n",
        "        lagschosen += [col for col in lagcols if str(lag) in col]\n",
        "        \n",
        "    lagschosen.sort()\n",
        "    sociocols = [col for col in list(dataframe.columns) if '2019' in col]\n",
        "    indices = ['Y-W','province']\n",
        "    y = f\"newcases_tplus{pred}\"\n",
        "    \n",
        "    allcols = indices + [y] + lagschosen + sociocols\n",
        "    \n",
        "    # Given lags, take out data that contains NaNs due to data unavailability\n",
        "    # First week when we have data is 2020-10, so add up weeks according to lags..\n",
        "    max_lag = max(lags)\n",
        "    # first_week = f\"2020-{10+max_lag}\"\n",
        "    first_week = '2021-01'\n",
        "    last_week = '2021-52'\n",
        "    \n",
        "    # Given that we are predicting into the future, we need to take off as many weeks as we\n",
        "    # are predicting into the future for, because otherwise we have NaNs..\n",
        "    last_week = f\"2022-{10-pred}\"\n",
        "    \n",
        "    # We also need to take care of the fact that we only have Google Mobility data up to 2021-52\n",
        "    last_week_google = f\"2021-52\"\n",
        "    \n",
        "    last_effective_week = [last_week,last_week_google]\n",
        "    last_effective_week.sort()\n",
        "    dataframe = dataframe[(dataframe['Y-W'] >= first_week) & (dataframe['Y-W'] <= last_effective_week[0])]\n",
        "    dataframe.reset_index(drop=True,inplace=True)\n",
        "    return dataframe[allcols],y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37070694",
      "metadata": {
        "id": "37070694"
      },
      "outputs": [],
      "source": [
        "data,depvarname = choosehorizon(df,2,[1,2,3,4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f5f2748",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f5f2748",
        "outputId": "2e84a44b-a99a-46ac-cf66-93ac9b3b1b1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52.0"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "data.shape[0]/18"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5aedd52",
      "metadata": {
        "id": "f5aedd52"
      },
      "source": [
        "## Training setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7125021",
      "metadata": {
        "id": "e7125021"
      },
      "outputs": [],
      "source": [
        "training_size = 30 # week\n",
        "testing_size = 1 # week\n",
        "num_counties = len(data.province.value_counts().index)\n",
        "time_steps = 22"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92595c57",
      "metadata": {
        "id": "92595c57"
      },
      "source": [
        "## Model tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "688c9ab0",
      "metadata": {
        "id": "688c9ab0"
      },
      "outputs": [],
      "source": [
        "train_r2_xgb = dict()\n",
        "train_rmse_xgb = dict()\n",
        "train_mae_xgb = dict()\n",
        "test_rmse_xgb = dict()\n",
        "test_mae_xgb = dict()\n",
        "tuned_params_xgb = dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "650be007",
      "metadata": {
        "id": "650be007"
      },
      "source": [
        "## Model grid setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0a6e436",
      "metadata": {
        "id": "f0a6e436"
      },
      "outputs": [],
      "source": [
        "# Setting Hyperparameters. Please refer to the SI for more information\n",
        "xgb_params = dict(learning_rate=np.arange(0.05,0.3,0.05),\n",
        "                    #  n_estimators=np.arange(150,400,100), \n",
        "                     gamma = np.arange(1,3,1),\n",
        "                     max_depth=[int(i) for i in np.arange(1,10,1)]) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DdJPVhjs8cd",
        "outputId": "ee4d20db-60cb-4145-999a-0b100158f927"
      },
      "id": "2DdJPVhjs8cd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gamma': array([1, 2]),\n",
              " 'learning_rate': array([0.05, 0.1 , 0.15, 0.2 , 0.25]),\n",
              " 'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9]}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0550cc7",
      "metadata": {
        "id": "b0550cc7"
      },
      "source": [
        "## Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a279471",
      "metadata": {
        "scrolled": true,
        "id": "7a279471"
      },
      "outputs": [],
      "source": [
        "for i in range(time_steps):\n",
        "    \n",
        "    training_df = data.iloc[:(i+training_size)*num_counties,:]\n",
        "    testing_df = data.iloc[(i+training_size)*num_counties:(i+training_size+testing_size)*num_counties,:]\n",
        "    \n",
        "#     start_time = time.time()\n",
        "\n",
        "    # in the 2-week prediction model, the target variable is LOG_DELTA_INC_RATE_T_14\n",
        "    X_train = training_df.iloc[:,3:]\n",
        "    y_train = training_df[depvarname]\n",
        "    X_test = testing_df.iloc[:,3:]\n",
        "    y_test = testing_df[depvarname]\n",
        "    \n",
        "    print(X_train.shape)\n",
        "    print(y_train.shape)\n",
        "    \n",
        "    print(X_test.shape)\n",
        "    print(y_test.shape)\n",
        "    \n",
        "    #scaling X\n",
        "    scaler = MinMaxScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "    \n",
        "    \n",
        "    #inititalization\n",
        "    xgb_model = xgboost.XGBRegressor(seed=42, verbosity=0)\n",
        "    \n",
        "    #cross validation\n",
        "    xgb_cv = GridSearchCV(xgb_model, xgb_params, \n",
        "                                    scoring='neg_root_mean_squared_error', n_jobs=-1, verbose=3)\n",
        "    \n",
        "    xgb_optimized = xgb_cv.fit(X_train, y_train)\n",
        "    best_xgb = xgb_optimized.best_estimator_\n",
        "    tuned_params_xgb['whole', i] = xgb_optimized.best_params_\n",
        "    \n",
        "    # model evaluation for training set\n",
        "    r2_train_xgb = round(best_xgb.score(X_train, y_train),2)\n",
        "    train_r2_xgb['whole', i] = r2_train_xgb\n",
        "    \n",
        "    y_train_predicted_xgb = best_xgb.predict(X_train)\n",
        "    rmse_train_xgb = (np.sqrt(mean_squared_error(y_train, y_train_predicted_xgb)))\n",
        "    train_rmse_xgb['whole', i] = rmse_train_xgbpd.get_dummies(moviegenres.apply(pd.Series).stack())\n",
        "    train_mae_xgb['whole', i] =  mean_absolute_error(y_train, y_train_predicted_xgb)\n",
        "\n",
        "\n",
        "    # model evaluation for test set\n",
        "    y_test_predicted_xgb = best_xgb.predict(X_test)\n",
        "    rmse_test_xgb = (np.sqrt(mean_squared_error(y_test, y_test_predicted_xgb)))\n",
        "    test_rmse_xgb['whole', i] = rmse_test_xgb\n",
        "    test_mae_xgb['whole', i] = mean_absolute_error(y_test, y_test_predicted_xgb)\n",
        "        \n",
        "    print(f\"Finished {i}th round...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_params_xgb"
      ],
      "metadata": {
        "id": "LT9i_DVA6lZ0"
      },
      "id": "LT9i_DVA6lZ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.exp(y_test_predicted_xgb - 1))\n",
        "print(np.exp(y_test - 1))"
      ],
      "metadata": {
        "id": "nfcMS58tqQ5q"
      },
      "id": "nfcMS58tqQ5q",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "prediction_work.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}